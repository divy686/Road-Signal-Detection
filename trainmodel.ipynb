{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92a3091-c118-4cba-b9db-146f7d936dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd54946-fea4-4b1e-a89f-307f36cf67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    classes = 43\n",
    "    for i in range(classes):\n",
    "        path = os.path.join(data_dir, str(i))\n",
    "        print(f\"Loading class {i}...\")  # ğŸŸ¨ progress track karne ke liye\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                image = cv2.imread(os.path.join(path, img))\n",
    "                image = cv2.resize(image, (32, 32))\n",
    "                X.append(image)\n",
    "                y.append(i)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29202ada-75ce-4f2f-ba05-ac2cc7d2fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class 0...\n",
      "Loading class 1...\n",
      "Loading class 2...\n",
      "Loading class 3...\n",
      "Loading class 4...\n",
      "Loading class 5...\n",
      "Loading class 6...\n",
      "Loading class 7...\n",
      "Loading class 8...\n",
      "Loading class 9...\n",
      "Loading class 10...\n",
      "Loading class 11...\n",
      "Loading class 12...\n",
      "Loading class 13...\n",
      "Loading class 14...\n",
      "Loading class 15...\n",
      "Loading class 16...\n",
      "Loading class 17...\n",
      "Loading class 18...\n",
      "Loading class 19...\n",
      "Loading class 20...\n",
      "Loading class 21...\n",
      "Loading class 22...\n",
      "Loading class 23...\n",
      "Loading class 24...\n",
      "Loading class 25...\n",
      "Loading class 26...\n",
      "Loading class 27...\n",
      "Loading class 28...\n",
      "Loading class 29...\n",
      "Loading class 30...\n",
      "Loading class 31...\n",
      "Loading class 32...\n",
      "Loading class 33...\n",
      "Loading class 34...\n",
      "Loading class 35...\n",
      "Loading class 36...\n",
      "Loading class 37...\n",
      "Loading class 38...\n",
      "Loading class 39...\n",
      "Loading class 40...\n",
      "Loading class 41...\n",
      "Loading class 42...\n",
      "âœ… Dataset loaded successfully!\n",
      "X shape: (39209, 32, 32, 3)\n",
      "y shape: (39209,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:/Users/LHCP/Desktop/road_signal_detection/dataset/Train\"\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ec4d54-f53f-4f1a-af05-4b810e4aac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data prepared successfully!\n",
      "Training data shape: (31367, 32, 32, 3)\n",
      "Validation data shape: (7842, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Normalize pixel values\n",
    "X = X / 255.0\n",
    "\n",
    "# Step 2: One-hot encode labels\n",
    "y = to_categorical(y, num_classes=43)\n",
    "\n",
    "# Step 3: Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… Data prepared successfully!\")\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef74f638-ebb3-45c0-a571-e8bcc139990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LHCP\\anaconda3\\envs\\road-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CNN model created and compiled!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Step: Create CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # to reduce overfitting\n",
    "model.add(Dense(43, activation='softmax'))  # 43 classes\n",
    "\n",
    "# Step: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"âœ… CNN model created and compiled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1015c317-e43a-4774-beeb-8d2f03a8ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.4707 - loss: 1.9189 - val_accuracy: 0.8623 - val_loss: 0.5971\n",
      "Epoch 2/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - accuracy: 0.7987 - loss: 0.6510 - val_accuracy: 0.9566 - val_loss: 0.2262\n",
      "Epoch 3/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - accuracy: 0.8757 - loss: 0.4016 - val_accuracy: 0.9675 - val_loss: 0.1365\n",
      "Epoch 4/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9079 - loss: 0.2961 - val_accuracy: 0.9712 - val_loss: 0.1051\n",
      "Epoch 5/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9258 - loss: 0.2389 - val_accuracy: 0.9824 - val_loss: 0.0819\n",
      "Epoch 6/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9393 - loss: 0.1948 - val_accuracy: 0.9869 - val_loss: 0.0611\n",
      "Epoch 7/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9488 - loss: 0.1627 - val_accuracy: 0.9897 - val_loss: 0.0438\n",
      "Epoch 8/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9547 - loss: 0.1458 - val_accuracy: 0.9855 - val_loss: 0.0523\n",
      "Epoch 9/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9572 - loss: 0.1349 - val_accuracy: 0.9909 - val_loss: 0.0404\n",
      "Epoch 10/10\n",
      "\u001b[1m491/491\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.9614 - loss: 0.1176 - val_accuracy: 0.9911 - val_loss: 0.0352\n"
     ]
    }
   ],
   "source": [
    "# Step: Train the CNN model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d16a42e-012e-4bdb-b2d2-5cb51171a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m246/246\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0352\n",
      "âœ… Validation Accuracy: 99.11%\n"
     ]
    }
   ],
   "source": [
    "# Step: Evaluate the trained model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(\"âœ… Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e3d5b5-ce6d-4f89-8e43-9192f48cbe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step: Save the trained model\n",
    "model.save(\"road_sign_cnn_model.h5\")\n",
    "print(\"âœ… Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605e822-514b-4ca7-879d-c05c1f72f6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:road-env]",
   "language": "python",
   "name": "conda-env-road-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
